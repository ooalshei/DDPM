{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f2c84cf-eae4-4317-869d-262a90b5ba09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7674a629-b1d4-4941-8244-d4686334957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self, root): #I think I got this, but ask about other arguments\n",
    "        self.data = np.load(root)\n",
    "        self.max_data = np.max(self.data, axis=0)\n",
    "        self.min_data = np.min(self.data, axis=0)\n",
    "        self.standardized_data = 2*(self.data - self.min_data)/(self.max_data - self.min_data) - 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data) #need to verify the index here\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.standardized_data[index]\n",
    "        return torch.from_numpy(x).float() #Ask here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b252f0-0b3e-4e8a-98b1-026e970b1977",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()      \n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        half_dim = self.dim // 2\n",
    "        emb = np.log(10000) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim) * -emb)\n",
    "        emb = x[:, None] * emb[None, :]\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0f65d95-cf08-460a-a20a-637d6a1c6100",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()                   #To inheret all the methods and properties of the parent class\n",
    "        self.layers = nn.Sequential(\n",
    "            #nn.Flatten(),                    #Do I need this?\n",
    "            nn.Linear(3,8),                     #What are the dimensions? Do they matter?\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32,16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8,3),\n",
    "        )\n",
    "             \n",
    "    def forward(self,x):                    #This feeds the data into the layers and returns the output\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace64571-c99a-4dc0-b5fd-31a14f640f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reparametrize(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_in, dim_out):\n",
    "        super().__init__()\n",
    "        self.dim_in = dim_in\n",
    "        self.dim_out = dim_out\n",
    "        \n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(dim_in, dim_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67779d5d-3d89-49b0-8aed-27f1835aff67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CombinedBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, data_dim_in, data_dim_out, time_dim_in, time_dim_out):\n",
    "        super().__init__()\n",
    "        self.data_dim_in = data_dim_in\n",
    "        self.data_dim_out = data_dim_out\n",
    "        self.time_dim_in = time_dim_in\n",
    "        self.time_dim_out = time_dim_out\n",
    "        \n",
    "        \n",
    "        self.data_layer = nn.Sequential(\n",
    "            nn.Linear(data_dim_in, data_dim_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.time_layer = nn.Sequential(\n",
    "            nn.Linear(time_dim_in, time_dim_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.combined_data_layer = nn.Sequential(\n",
    "            nn.Linear(data_dim_out, data_dim_out),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, time_emb):\n",
    "        h_data = self.data_layer(x)\n",
    "        h_time = self.time_layer(t_emb)\n",
    "        combined_output = h_data + h_time\n",
    "        out = self.combined_data_layer(combined_output)\n",
    "        return out\n",
    "\n",
    "class MLPModule(nn.Module):\n",
    "    \n",
    "    def __init__(self, dim_list = [4,8,16,32,64,128]):\n",
    "        super().__init__()\n",
    "        self.block_list = nn.ModuleList()\n",
    "        \n",
    "        upsample, downsample = dim_list, dim_list[::-1]\n",
    "        \n",
    "        for data_dim_in, data_dim_out in zip(upsample[:-1], upsample[1:]):\n",
    "            self.block_list.append(CombinedBlock(data_dim_in, data_dim_out, dim_list[0], data_dim_out))\n",
    "        for data_dim_in, data_dim_out in zip(downsample[:-1], downsample[1:]):\n",
    "            self.block_list.append(CombinedBlock(data_dim_in, data_dim_out, dim_list[0], data_dim_out))\n",
    "            \n",
    "            \n",
    "    def forward(self, x, t_emb):\n",
    "        \n",
    "        for block in self.block_list:\n",
    "            x = block(x, t_emb)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3db4ed6-438c-4d09-96aa-73ddf8022821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':        What is this??\n",
    "  \n",
    "#   # Set fixed random number seed\n",
    "#   torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d778cb8-49cc-4682-bd19-52398c93f9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data=MBDataSet('data.npy')\n",
    "train_dataloader = DataLoader(training_data, batch_size=100, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35c2bd3d-b648-4dd0-8a47-d8cca9806ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rp_i = Reparametrize(3,4)\n",
    "rp_f = Reparametrize(4,3)\n",
    "spm = SinusoidalPosEmb(4)\n",
    "mlp = MLPModule()\n",
    "\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-4)     #preferences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4813597-eef8-4427-a464-ad0ce1c26012",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(5):             #Preferences?\n",
    "    \n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs = rp_i(data)\n",
    "        t = torch.rand(1)\n",
    "        t_emb = spm(t)\n",
    "        targets = torch.normal(0, 1, size=(100,3))\n",
    "        optimizer.zero_grad()\n",
    "        outputs_prime = mlp(inputs, t_emb) #inputs should be corrupted data not original data\n",
    "        outputs = rp_f(outputs_prime)\n",
    "        loss = loss_function(outputs, targets)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc3ed5-4675-4fe4-b5e5-845ba86cca78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
